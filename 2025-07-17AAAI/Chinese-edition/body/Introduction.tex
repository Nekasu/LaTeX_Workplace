\section{Introduction}

Neural style transfer (NST) reimagines visual content by synthesizing the semantics of one image with the artistic identity of another using deep neural networks. 
Since the seminal work of Gatys et al.~\cite{gatys2016image}, which framed style transfer as an optimization problem using the Gram matrix of VGG features, the field has advanced significantly toward real-time stylization~\cite{huang2017arbitrary}, high-fidelity generation~\cite{kwon2024aesfa}, and multimodal controllability~\cite{ahn2024dreamstyler}.

However, a critical limitation underlies almost all existing NST models: the assumption that input images are fully opaque. This design paradigm excludes the alpha channel—a key component in digital imaging that encodes per-pixel transparency and is widely used in UI composition, image compositing, and layered artistic workflows. As a result, standard NST methods ignore transparency semantics, which often leads to undesirable stylization artifacts such as edge bleeding, occluded detail transfer, and inconsistency in downstream composition.

Unlike RGB channels that define visual appearance, the alpha channel governs perceptual visibility. In the context of style transfer, alpha values modulate stylistic salience—pixels with high alpha demand stronger stylization fidelity, while those with low or zero alpha suppress stylistic rendering. This transparency signal encodes important spatial semantics that are entirely discarded in RGB-only NST pipelines.

To address this gap, we introduce \textbf{alpha-aware neural style transfer}—a novel NST paradigm that models transparency semantics throughout the stylization process. Our end-to-end framework accepts RGBA inputs, applies alpha-guided feature computation, and outputs stylized RGBA images that faithfully preserve both artistic identity and transparency structure. To our knowledge, this is the first NST method to treat soft alpha information as a first-class modeling component.

While our study focuses on the alpha channel as a prominent transparency cue, we view our design as a first step toward modeling more general per-pixel semantics such as depth, surface normals, or material attributes. We leave these extensions for future work.

\textbf{Our contributions are summarized as follows:}
\begin{itemize}
    \item \textbf{Problem formulation}: We define alpha-aware neural style transfer as a new task setting that extends traditional RGB-only NST to RGBA-space modeling with explicit transparency semantics.
    
    \item \textbf{Soft Partial Convolution}: We propose a soft partial convolution module that generalizes conventional partial convolutions to handle continuous-valued alpha masks, enabling effective feature propagation under partial visibility.
    
    \item \textbf{Alpha-guided perceptual loss}: We design an alpha-aware perceptual loss that modulates stylization supervision based on transparency, encouraging semantic consistency between visibility and stylized output.
    
    \item \textbf{AlphaStyle Dataset}: We construct AlphaStyle, the first large-scale RGBA dataset for NST, derived from WikiArt and MSCOCO using Segment Anything~\cite{kirillov2023segment} to extract irregular masks. The dataset contains over 20,000 high-quality RGBA image pairs in lossless PNG format.
\end{itemize}